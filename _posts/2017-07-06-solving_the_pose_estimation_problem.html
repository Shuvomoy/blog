---
layout: post
title: Solving the Pose Estimation Problem using Singular Value Decomposition
categories: [optimization]
tags: [optimization]
comments: true
---
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>
<p>The pose estimation problem is a type of matching problem that shows up in many fields, <em>e.g.,</em> robotics, computer vision, manufacturing. In this blog, we will solve the problem using singular value decomposition. <!-- more --> Let us define matrix <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, where each of their columns represents a three-dimensional point, as follows.</p>
<p><span class="math display">\[\begin{aligned}
 &amp; A=\begin{bmatrix}a_{1} &amp; \cdots &amp; a_{m}\end{bmatrix}\in\mathbf{R}^{n\times m},\\
 &amp; B=\begin{bmatrix}b_{1} &amp; \cdots &amp; b_{m}\end{bmatrix}\in\mathbf{R}^{n\times m}.\end{aligned}\]</span></p>
<p>So, both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are collection of <span class="math inline">\(m\)</span> three dimensional points with <span class="math inline">\(n=3\)</span>. The pose estimation is associated with the determination with a rigid rotation and a translation of the point set <span class="math inline">\(B\)</span>, which will approximately bring the transformed points to the point set <span class="math inline">\(A\)</span>. Let us denote the rotation matrix by <span class="math inline">\(R\in\mathbf{R}^{n\times n}\)</span> (satisfies <span class="math inline">\(R^{T}R=I_{n}\)</span>), and the translation vector by <span class="math inline">\(t\in\mathbf{R}^{n}\)</span>; they are our decision variable in the following optimization problem:</p>
<p><span class="math display">\[\begin{aligned}
\begin{aligned} &amp; \mathrm{minimize}_{R,t} &amp;  &amp; \|A-RB-t\boldsymbol{1}^{T}\|_{F}^{2}\\
 &amp; \mathrm{subject\;to} &amp;  &amp; R^{T}R=I_{n}\\
 &amp;  &amp;  &amp; R\in\mathbf{R}^{n\times n},t\in\mathbf{R}^{n}.
\end{aligned}
\qquad(1)\end{aligned}\]</span></p>
<p>Where the notation <span class="math inline">\(\|\cdot\|_{F}\)</span> denotes the Froebenius norm which has the definition: <span class="math inline">\(\|G\|_{F}^{2}=\mathrm{tr}(G^{T}G)\)</span> for any matrix <span class="math inline">\(B\)</span>, with the property: <span class="math inline">\(\|G+H\|_{F}^{2}=\|G\|_{F}^{2}+\|H\|_{F}^{2}+2\mathrm{tr}(GH^{T})\)</span>. Also <span class="math inline">\(\boldsymbol{1}\)</span> is an <span class="math inline">\(m\)</span> dimensional column of 1s.</p>
<p>Suppose <span class="math inline">\(R\)</span> is fixed. First note that the objective can be expanded as follows:</p>
<p><span class="math display">\[\begin{aligned}
 &amp; \|(A-RB)+(-t\boldsymbol{1}^{T})\|_{F}^{2}\\
= &amp; \|A-RB\|_{F}^{2}+\underbrace{\|t\boldsymbol{1}^{T}\|_{F}^{2}}_{=mt^{T}t}+2\mathrm{tr}(A-RB)(-t\boldsymbol{1}^{T})^{T}\\
= &amp; \|A-RB\|_{F}^{2}+mt^{T}t-2\mathrm{tr}(A-RB)\boldsymbol{1}t^{T},\end{aligned}\]</span></p>
<p>which can minimized with respect to <span class="math inline">\(t\)</span> by setting the gradient of the last line with respect to <span class="math inline">\(t\)</span> to zero, and then solving for <span class="math inline">\(t\)</span> for any fixed <span class="math inline">\(R\)</span> as follows:</p>
<p><span class="math display">\[\begin{aligned}
 &amp; 2mt-2(A-RB)\boldsymbol{1}=0\\
\Rightarrow &amp; t=\frac{1}{m}(A-RB)\boldsymbol{1}.\qquad(2)\end{aligned}\]</span></p>
<p>So, Equation (2) gives us the optimal translation vector as a function of the rotation matrix. Now we substitute <span class="math inline">\(t\)</span> from Equation (2) in the objective function in problem (1), and obtain the objective function with respect to <span class="math inline">\(R\)</span> as follow:</p>
<p><span class="math display">\[\begin{aligned}
 &amp; \|A-RB-t\boldsymbol{1}^{T}\|_{F}^{2}\\
= &amp; \|A-RB-t\frac{1}{m}(A-RB)\boldsymbol{1}\boldsymbol{1}^{T}\|_{F}^{2}\\
= &amp; \|(A-RB)(I_{m}-\frac{1}{m}\boldsymbol{1}\boldsymbol{1}^{T})\|_{F}^{2}\\
= &amp; \|\underbrace{A(I_{m}-\frac{1}{m}\boldsymbol{1}\boldsymbol{1}^{T})}_{\tilde{A}}-R\underbrace{B(I_{m}-\frac{1}{m}\boldsymbol{1}\boldsymbol{1}^{T})}_{\tilde{B}}\|_{F}^{2}\\
= &amp; \|\tilde{A}-R\tilde{B}\|_{F}^{2}.\end{aligned}\]</span></p>
<p>So, optimization problem (1) now becomes:</p>
<p><span class="math display">\[\begin{aligned}
 &amp; \begin{aligned} &amp; \mathrm{minimize}_{R} &amp;  &amp; \|\tilde{A}-R\tilde{B}\|_{F}^{2}\\
 &amp; \mathrm{subject\;to} &amp;  &amp; R^{T}R=I_{n}\\
 &amp;  &amp;  &amp; R\in\mathbf{R}^{n\times n}.
\end{aligned}
\qquad(3)\end{aligned}\]</span></p>
<p>Suppose the matrix <span class="math inline">\(\tilde{B}\tilde{A}^{T}\in\mathbf{R}^{n\times n}\)</span>with rank <span class="math inline">\(r\)</span> has the following singular value decomposition: <span class="math inline">\(\tilde{B}\tilde{A}^{T}=U\Sigma V^{T}\)</span> with</p>
<ul>
<li><p><span class="math inline">\(U\in\mathbf{R}^{n\times n}\)</span> satisfying <span class="math inline">\(U^{T}U=I_{n}\)</span>,</p></li>
<li><p><span class="math inline">\(V\in\mathbf{R}^{n\times n}\)</span> satisfying <span class="math inline">\(V^{T}V=I_{n}\)</span>, and</p></li>
<li><p><span class="math inline">\(\Sigma=\mathrm{diag}(\sigma_{1},\sigma_{2},\ldots,\sigma_{r},0,\ldots,0)=\mathbf{R}^{n\times n}\)</span> with the first <span class="math inline">\(r\)</span> diagonal components begin strictly positive.</p></li>
</ul>
<p>Now let us expand the objective in problem (3) as follows:</p>
<p><span class="math display">\[\begin{aligned}
 &amp; \|\tilde{A}-R\tilde{B}\|_{F}^{2}\\
= &amp; \|\tilde{A}\|_{F}^{2}+\|R\tilde{B}\|_{F}^{2}-2\mathrm{tr}(\tilde{A}^{T}R\tilde{B})\\
= &amp; \|\tilde{A}\|_{F}^{2}+\|\tilde{B}\|_{F}^{2}-2\mathrm{tr}(\tilde{B}\tilde{A}^{T}R)\\
= &amp; \|\tilde{A}\|_{F}^{2}+\|\tilde{B}\|_{F}^{2}-2\underbrace{\mathrm{tr}(U\Sigma V^{T}R)}_{\mathrm{tr}(\Sigma V^{T}RU)}\\
= &amp; \|\tilde{A}\|_{F}^{2}+\|\tilde{B}\|_{F}^{2}-2\mathrm{tr}(\Sigma\underbrace{V^{T}RU}_{Q})\\
= &amp; \|\tilde{A}\|_{F}^{2}+\|\tilde{B}\|_{F}^{2}-2\mathrm{tr}(\Sigma Q)\qquad(4)\end{aligned}\]</span></p>
<p>Between line 2 and 3 of the expansion above we have used the following facts:</p>
<ul>
<li><p>Applying a rotation matrix does not change norm of a matrix, so <span class="math inline">\(\|R\tilde{B}\|_{F}^{2}=\|\tilde{B}\|^{2}\)</span>.</p></li>
<li><p>The matrices in a trace of a product can be switched without changing the result, so <span class="math inline">\(\mathrm{tr}(GH)=\mathrm{tr}(HG)\)</span>.</p></li>
</ul>
<p>Now in the expanded objective in (4), <span class="math inline">\(Q=V^{T}RU\)</span> is another orthogonal matrix satisfying <span class="math inline">\(Q^{T}Q=I_{n}\)</span>, and <span class="math inline">\(\Sigma=\mathrm{diag}(\sigma_{1},\sigma_{2},\ldots,\sigma_{r})\)</span> is a diagonal matrix. As <span class="math inline">\(\mathrm{tr}(AB)=\sum_{i}(AB)_{i}\)</span>, we have <span class="math inline">\(\mathrm{tr}(\Sigma Q)=\sum_{i=1}^{r}Q_{ii}\sigma_{i}\)</span>. Clearly the objective in (4) will be minimized if <span class="math inline">\(\mathrm{tr}(\Sigma Q)=\sum_{i=1}^{r}Q_{ii}\sigma_{i}\)</span> is maximized. As <span class="math inline">\(Q\)</span> is orthogonal, we have <span class="math inline">\(|Q_{ii}|\leq1\)</span>, and <span class="math inline">\(\sigma_{i}\geq0\)</span> by definition, the mentioned term will be maximized if and only if we set each <span class="math inline">\(Q_{ii}=1\)</span>, <em>i.e.,</em> <span class="math inline">\(Q=V^{T}RU=I_{n}\)</span>, this is only possible if we set <span class="math inline">\(R=VU^{T}\)</span> because then <span class="math inline">\(Q=V^{T}RU=\underbrace{V^{T}V}_{I_{n}}\underbrace{U^{T}U}_{I_{n}}=I_{n}\)</span>, where we have used the properties of singular value decomposition mentioned above. So, the optimal solutions for <span class="math inline">\(R^{*}\)</span> and <span class="math inline">\(t^{*}\)</span> are:</p>
<p><span class="math display">\[\begin{aligned}
 &amp; R^{*}=VU^{T},\end{aligned}\]</span></p>
<p>(where <span class="math inline">\(V,U\)</span> come from singular value decomposition of <span class="math inline">\(\tilde{B}\tilde{A}^{T}=U\Sigma V^{T}\)</span>), and</p>
<p><span class="math display">\[\begin{aligned}
 &amp; t^{*}=\frac{1}{m}(A-R^{*}B)\boldsymbol{1}.\end{aligned}\]</span></p>
</body>
</html>
