<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
     <link rel="stylesheet" href="/libs/highlight/github.min.css">
   
    <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/tufte.css">
<link rel="stylesheet" href="/css/latex.css">
<link rel="stylesheet" href="/css/adjust.css"> <!-- sheet to overwrite some clashing styles -->
<link rel="icon" href="/assets/favicon.png">

     <title>Running parallel Julia code on MIT Engaging</title>  
</head>

<body>
<div id="layout">
  <div id="menu">
    <ul>
      <li><a href="/">Home</a></li>
      <li><a href="/tags/">Tags</a></li>
    </ul>
  </div>
  <div id="main">



<!-- Content appended here -->
<div class="franklin-content"><h1 id="running_parallel_julia_code_on_mit_engaging"><a href="#running_parallel_julia_code_on_mit_engaging" class="header-anchor">Running parallel Julia code on MIT Engaging</a></h1>
<p><strong>Shuvomoy Das Gupta</strong></p>
<p><em>February 1, 2021</em></p>
<p>In this blog, we will discuss how to run  parallel <code>Julia</code> code on MIT Engaging. </p>
<hr />
<p><strong>Table of contents</strong></p>
<div class="franklin-toc"><ol><li><a href="#setup">Setup</a></li><li><a href="#shell_script_to_submit_the_job">Shell script to submit the job</a></li><li><a href="#submitting_the_job">Submitting the job</a></li></ol></div>
<hr />
<h2 id="setup"><a href="#setup" class="header-anchor">Setup</a></h2>
<p>We can achieve this task by using parallelization techniques provided in <code>Julia</code>. For this blog, we will consider <code>pmap</code>. In the following code, we create 10 large matrices and then perform a singular value decomposition on each. We will show that parallelizing this computation can attain significant speedup simply.</p>
<p><strong>Julia Code.</strong> The code for the <code>Julia</code> file is given below. Please save it in a text file and name it <code>pmap_julia.jl</code>. </p>
<pre><code class="language-julia">using ClusterManagers,Distributed, BenchmarkTools

# Add in the cores allocated by the scheduler as workers

addprocs&#40;SlurmManager&#40;parse&#40;Int,ENV&#91;&quot;SLURM_NTASKS&quot;&#93;&#41;-1&#41;&#41;

print&#40;&quot;Added workers: &quot;&#41;

println&#40;nworkers&#40;&#41;&#41;

using LinearAlgebra # Load the package centrally

@everywhere using LinearAlgebra # load it on each process

# DATA GENERATION: The following code will be run only on one core
# ----------------------------------------------------------------

# create the array of random initial points
X_array&#61;&#91;rand&#40;100,100&#41; for i in 1:10&#93;

# benchmark serial implementation
b1 &#61; @benchmark map&#40;svd, X_array&#41;

println&#40;&quot;benchmark for serial code&quot;&#41;
println&#40;&quot;*************************&quot;&#41;
io &#61; IOBuffer&#40;&#41;
show&#40;io, &quot;text/plain&quot;, b1&#41;
s &#61; String&#40;take&#33;&#40;io&#41;&#41;
println&#40;s&#41;

# benchmark parallel implementation
b2 &#61; @benchmark pmap&#40;svd, X_array&#41;

println&#40;&quot;benchmark for parallel code&quot;&#41;
println&#40;&quot;***************************&quot;&#41;
io &#61; IOBuffer&#40;&#41;
show&#40;io, &quot;text/plain&quot;, b2&#41;
s &#61; String&#40;take&#33;&#40;io&#41;&#41;
println&#40;s&#41;</code></pre>
<p>Note that in the first line, we have loaded the packages that we use. If they are not installed, you can install them by running the following commands from <code>bash</code>. </p>
<pre><code class="language-julia">srun --pty -p sched_mit_sloan_interactive julia</code></pre>
<p>This will start a <code>Julia REPL</code> in <code>bash</code>. Run the following commands: </p>
<pre><code class="language-julia">&#93; add ClusterManagers,Distributed, BenchmarkTools</code></pre>
<h2 id="shell_script_to_submit_the_job"><a href="#shell_script_to_submit_the_job" class="header-anchor">Shell script to submit the job</a></h2>
<p>Now we are going to create a shell script that will be used to submit the job. The code for the shell script is below. Please save it in a text file, and name it <code>run_pmap_julia.sh</code>. In the code, <code>SBATCH -o pmap_julia.log-&#37;j</code> indicates the name of the file where the output is written, and <code>SBATCH -n 14</code> indicates the number of cores or cpus allocated to the job. </p>
<pre><code class="language-julia">#&#33;/bin/bash

# Slurm sbatch options
#SBATCH -o pmap_julia_log-&#37;j.txt
#SBATCH -n 14

# Initialize the module command first source
source /etc/profile

# Load Julia Module
module load julia/1.5.2
   
 
# Call your script as you would from the command line
# Call your script as you would from the command line
julia pmap_julia.jl</code></pre>
<h2 id="submitting_the_job"><a href="#submitting_the_job" class="header-anchor">Submitting the job</a></h2>
<p>Now log in to MIT engaging, copy the files created above to your working directory, and run the following command. Ensure that the <code>pwd</code> command results in the working directory, else use the command <code>cd directory_that_contains_the_code</code> to change the working directory.</p>
<pre><code class="language-julia">sbatch run_pmap_julia.sh</code></pre>
<p>That&#39;s it&#33; Once the computation is done, we see from the output log file that parallelization has decreased the computation time significantly: </p>
<pre><code class="language-julia">benchmark for serial code
*************************
BenchmarkTools.Trial: 
  memory estimate:  4.71 MiB
  allocs estimate:  102
  --------------
  minimum time:     52.735 ms &#40;0.00&#37; GC&#41;
  median time:      53.473 ms &#40;0.00&#37; GC&#41;
  mean time:        53.792 ms &#40;0.15&#37; GC&#41;
  maximum time:     56.662 ms &#40;4.62&#37; GC&#41;
  --------------
  samples:          93
  evals/sample:     1
    
benchmark for parallel code
***************************
BenchmarkTools.Trial: 
  memory estimate:  1.60 MiB
  allocs estimate:  1436
  --------------
  minimum time:     6.624 ms &#40;0.00&#37; GC&#41;
  median time:      6.927 ms &#40;0.00&#37; GC&#41;
  mean time:        7.172 ms &#40;0.78&#37; GC&#41;
  maximum time:     12.139 ms &#40;0.00&#37; GC&#41;
  --------------
  samples:          697
  evals/sample:     1</code></pre>
<p>where we see that the parallel code is more than 7 times faster than that of the serial code&#33;</p>
<div class="page-foot">
  <div class="copyright">
    &copy; Shuvomoy Das Gupta. Last modified: May 20, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div><!-- CONTENT ENDS HERE -->
        </div> <!-- end of id=main -->
    </div> <!-- end of id=layout -->
    
    
        <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

    
  </body>
</html>
